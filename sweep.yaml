# W&B Sweep Configuration for Stance Classifier
# Usage: wandb sweep sweep.yaml
#        wandb agent <sweep_id>
#
# Sweep v3: Final fine-tuning based on sweep v2 results
# - Fixed: attention targets, weighted_ce loss (clear winners)
# - Fine-tuning: lr, lora_r (16-24 sweet spot), warmup, weight_decay

project: NLP_cswk
entity: theo-farrell99-durham-university
method: bayes
metric:
  name: val/macro_f1
  goal: maximize

program: classifier.py
command:
  - ${env}
  - ${interpreter}
  - ${program}
  - "--agent"

parameters:
  model_name:
    value: "bertweet-large"
  lora_targets:
    value: "attention"  # Fixed - clear winner from sweep v2
  learning_rate:
    values: [0.00003, 0.00004, 0.00005]  # Narrow around best (4e-05)
  batch_size:
    value: 8
  num_epochs:
    value: 20
  warmup_ratio:
    values: [0.1, 0.15, 0.2]  # Fine-tune around 0.15
  weight_decay:
    values: [0.03, 0.05, 0.07]  # Fine-tune around 0.05
  lora_r:
    values: [12, 16, 20, 24]  # Focus on sweet spot
  lora_alpha:
    values: [48, 64, 80]  # Keep ~3-4x ratio to r
  loss_type:
    value: "weighted_ce"  # Fixed - clear winner from sweep v2
  early_stopping_patience:
    value: 3
